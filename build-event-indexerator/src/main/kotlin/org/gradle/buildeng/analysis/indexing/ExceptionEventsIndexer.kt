package org.gradle.buildeng.analysis.indexing

import com.google.api.services.bigquery.model.TableFieldSchema
import com.google.api.services.bigquery.model.TableRow
import com.google.api.services.bigquery.model.TableSchema
import org.apache.beam.runners.dataflow.options.DataflowPipelineOptions
import org.apache.beam.sdk.coders.Coder
import org.apache.beam.sdk.io.FileIO
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO
import org.apache.beam.sdk.io.gcp.bigquery.TableRowJsonCoder
import org.apache.beam.sdk.options.Default
import org.apache.beam.sdk.options.Description
import org.apache.beam.sdk.options.Validation
import org.apache.beam.sdk.transforms.Filter
import org.apache.beam.sdk.transforms.MapElements
import org.apache.beam.sdk.transforms.SerializableFunction
import org.apache.beam.sdk.values.KV
import org.apache.beam.sdk.values.TypeDescriptors.kvs
import org.apache.beam.sdk.values.TypeDescriptors.strings
import org.gradle.buildeng.analysis.transform.ExceptionDataEventsJsonTransformer
import java.io.ByteArrayInputStream
import java.io.IOException
import java.nio.charset.StandardCharsets
import java.util.*


object ExceptionEventsIndexer {
    @JvmStatic
    fun main(args: Array<String>) {

        val fieldSchema = ArrayList<TableFieldSchema>()
        fieldSchema.add(TableFieldSchema().setName("exceptionId").setType("STRING").setMode("REQUIRED"))
        fieldSchema.add(TableFieldSchema().setName("className").setType("STRING").setMode("NULLABLE"))
        fieldSchema.add(TableFieldSchema().setName("message").setType("STRING").setMode("NULLABLE"))
        fieldSchema.add(TableFieldSchema().setName("stacktrace").setType("RECORD").setMode("NULLABLE").setFields(listOf(
                TableFieldSchema().setName("stackTraceId").setType("STRING").setMode("REQUIRED"),
                TableFieldSchema().setName("stackFrames").setType("RECORD").setMode("REPEATED").setFields(listOf(
                        TableFieldSchema().setName("stackFrameId").setType("STRING").setMode("REQUIRED"),
                        TableFieldSchema().setName("declaringClass").setType("STRING").setMode("NULLABLE"),
                        TableFieldSchema().setName("methodName").setType("STRING").setMode("NULLABLE"),
                        TableFieldSchema().setName("fileName").setType("STRING").setMode("NULLABLE"),
                        TableFieldSchema().setName("lineNumber").setType("INTEGER").setMode("NULLABLE"),
                        TableFieldSchema().setName("fileRef").setType("STRING").setMode("NULLABLE")
                ))
        )))
        fieldSchema.add(TableFieldSchema().setName("causes").setType("STRING").setMode("REPEATED"))
        fieldSchema.add(TableFieldSchema().setName("metadata").setType("STRING").setMode("NULLABLE"))
        fieldSchema.add(TableFieldSchema().setName("classLevelAnnotations").setType("STRING").setMode("REPEATED"))

        val tableSchema = TableSchema()
        tableSchema.fields = fieldSchema

        val targetEventTypeMarker = "\"eventType\":\"ExceptionData\""

        val (pipe, options) = KPipe.from<TaskEventsTransformerOptions>(args)

        // NOTE: We are using FileIO here to read whole files and filter lines rather than reading using TextIO because using TextIO encounters an Error:
        //       "Total size of the BoundedSource objects generated by split() operation is larger than the allowable limit."
        //       See https://cloud.google.com/dataflow/docs/guides/troubleshooting-your-pipeline#total_number_of_boundedsource_objects_generated_by_splitintobundles_operation_is_larger_than_the_allowable_limit_or_total_size_of_the_boundedsource_objects_generated_by_splitintobundles_operation_is_larger_than_the_allowable_limit
        pipe.apply(FileIO.match().filepattern(options.inputFilePattern))
                .apply(FileIO.readMatches())
                .apply(MapElements.into(kvs(strings(), strings())).via(SerializableFunction { file: FileIO.ReadableFile ->
                    KV.of(file.metadata.resourceId().toString(), file.readFullyAsUTF8String())
                }))
                .apply("Include only builds with exceptions", Filter.by(SerializableFunction {
                    it.value.contains(targetEventTypeMarker)
                }))
                .flatMap { kv ->
                    val input = kv.value
                            .split("\n")
                            .find { line -> line.contains(targetEventTypeMarker) }
                    ExceptionDataEventsJsonTransformer().transform(input!!) }
                .map { convertJsonToTableRow(it) }
                .apply("Write to BigQuery", BigQueryIO.writeTableRows()
                        .withExtendedErrorInfo()
                        .withSchema(tableSchema)
                        .to(options.output)
                        .withCreateDisposition(BigQueryIO.Write.CreateDisposition.CREATE_IF_NEEDED)
                        .withWriteDisposition(BigQueryIO.Write.WriteDisposition.WRITE_TRUNCATE)
                )

        pipe.run().waitUntilFinish()
    }

    /**
     * Converts a JSON string to a [TableRow] object. If the data fails to convert, a RuntimeException will be thrown.
     *
     * @param json The JSON string to parse.
     * @return The parsed [TableRow] object.
     */
    private fun convertJsonToTableRow(json: String): TableRow? {
        // TODO: avoid converting to JSON => String => JSON again
        var row: TableRow? = null
        try {
            ByteArrayInputStream(json.toByteArray(StandardCharsets.UTF_8)).use { inputStream ->
                row = TableRowJsonCoder.of().decode(inputStream, Coder.Context.OUTER)
            }
        } catch (e: IOException) {
            throw RuntimeException("Failed to serialize json to table row: $json", e)
        }

        return row
    }

    interface TaskEventsTransformerOptions : DataflowPipelineOptions {
        // TODO: allow this input to be specified on the CLI
        @get:Description("The GCS location of the text you'd like to process")
        @get:Default.String("gs://gradle-task-test-cache-events-raw/*.txt")
        var inputFilePattern: String

        @get:Description("Output table to write to")
        @get:Validation.Required
        var output: String
    }
}
