= Gradle Build Analysis Project

The purpose of this project is to provide data for developer productivity by collecting and reporting:

 * What are the costliest tasks (time x frequency) of local developers, by project?
 ** What is the breakdown of these tasks in terms of cache effectiveness, network, something else?
 ** Given a task, tell me the cache rate, mean/stddev/histogram, inputs, network, etc. How has this changed over time?
 * What are the costliest errors (again, time x frequency) and build failures, segmented by environment and failure type?
 ** What is the impact of flaky test failures on local builds?
 * What versions of Gradle BT are in use at Gradle, and with what frequency? Similarly, what versions of guava are in use at Gradle across among active projects?

These applications collect and index Gradle Enterprise and GitHub events data into Google Cloud Storage and BigQuery.

This is separate from the CI Health project because it deals more directly with local development infrastructure.
A project separate from the dotcom/export-api-app was needed to allow this to be presentable for users and to provide real-world feedback on the GE export API.

== Querying the data
You can query build data using:

 * Google Cloud Project: `build-analysis`
 * BigQuery Dataset: `gradle_builds`
 * BigQuery Tables: `builds_YYYYMMDD`

Some fields are JSON. See link:https://cloud.google.com/bigquery/docs/reference/standard-sql/json_functions[BigQuery JSON functions] for reference.

== Project structure

==== Build Event Collector app
This application is responsible for streaming build event data from a configured Gradle Enterprise export API endpoint into a specified Google Cloud Storage bucket.
It pulls all builds down and all configured event types, avoiding as much data interaction (parsing, filtering) as possible.

Reference Materials:

 * link:https://docs.gradle.com/enterprise/export-api/[Gradle Enterprise Export API Manual]
 * link:https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-java[Google Cloud Storage docs]

==== Build Event Indexer apps
These applications are responsible for transforming raw data and indexing in Google BigQuery.
Each application consists of a `BuildTransformer` which filters and transforms the data and stores it, and a `BuildIndexer` which submits a job to index data using in BigQuery using a given schema (recommended) or auto-detected.

Reference Materials:

 * link:https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-json[Loading JSON data into BigQuery]

// TODO: document running Dataflow jobs
[listing]
====
./gradlew runJob --args="--runner=DirectRunner --project=build-analysis --output=gs://gradle-build-events/transformed"
./gradlew :test-event-indexerator:runJob --args="--runner=DataflowRunner --project=build-analysis --output=build-analysis:gradle_builds.tests_20190116 --tempLocation=gs://gradle-build-events/tmp12"
====

==== Build Producerator app
This app is not necessary right now. It streamed build events to Google Cloud PubSub to allow fanout with many build event collectors.

Currently the limiting factor is network outbound from the Gradle Enterprise server and multiple downloaders do not make processing faster.

// TODO: collect dependency and plugin applications data
// todo: collect raw events into day-segmented bucket keys
// TODO: Check out Cloud Datalab for viz: https://cloud.google.com/datalab/
// TODO: refactor indexing apps
// TODO: maybe re-index tests data with local changes?
// TODO: document indexing apps
// TODO: generate JSON and BigQuery models from POKOs: https://github.com/eonuora/bigquery-object-mapper/blob/master/src/main/java/com/ekene/bq/gcloud/BigQueryObjectMapper.java
// TODO: dashboard application which hits BigQuery and produces slick charts
// TODO: example queries for
// "What versions of library X are in use, how frequently, and (maybe) which projects?"
// "How frequent does buildSrc compilation happen locally?"
// "Whatâ€™s the flakiness rate over all branches?"
// "How many flaky tests are there per day/per week over all branches?"
// "Did any tasks become slower over the course of the last weeks?"
// "What is the average download speed from the remote cache? Are there some machines/times when it is slower?"
// "how parallel does work happen inside a Gradle build?"
// IDEA: GZoltar is looking into relating code changes to failures: http://www.gzoltar.com/publications.html
// IDEA: look into BigQueryML for flaky test detection: https://cloud.google.com/bigquery/docs/bigqueryml-scientist-start and https://cloud.google.com/blog/products/gcp/preparing-and-curating-your-data-for-machine-learning
// IDEA: calculate the cost of a given commit or PR
// IDEA: can we find problematic areas of the codebase by looking at the build data?
// IDEA: calculate the cost of changing a dependency
// IDEA: Can we easily detect bad practices? Not using the Daemon or Cold Daemon. No build cache, etc?

== Development

=== Prerequisites

 * Gradle Enterprise Export API access
 * Google Cloud build-analysis project access

=== Google Cloud initial setup
```sh
gcloud config set compute/zone us-central1-f
gcloud config set compute/region us-central1
```

=== Publishing to Google Cloud

_NOTE: Make sure you're logged into Google Cloud first._

```sh
./gradlew publish
```

This will publish distZips for all apps to a Maven repository at `gcs://gradle-build-analysis-apps/maven2`

=== Running applications in Google Cloud

==== Running Build Event Collector
```sh
gcloud compute instances create build-event-collectorator1 \
   --preemptible \
   --image-family debian-9 \
   --image-project debian-cloud \
   --machine-type n1-standard-8 \
   --scopes "userinfo-email,cloud-platform" \
   --metadata startup-script='#!/bin/sh
APP_NAME="build-event-collectorator"
APP_VERSION="0.3.4"
export GRADLE_ENTERPRISE_HOSTNAME="gradle-enterprise.mycompany.com"
export GRADLE_ENTERPRISE_USERNAME="my-username"
export GRADLE_ENTERPRISE_PASSWORD="my-password"
export GCS_RAW_BUCKET_NAME="gradle-task-test-cache-events-raw"
gsutil cp "gs://gradle-build-analysis-apps/maven2/org/gradle/buildeng/analysis/${APP_NAME}/${APP_VERSION}/${APP_NAME}-${APP_VERSION}.zip" .
apt-get update && apt-get -y --force-yes install openjdk-8-jdk unzip
update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
echo "Running ${APP_NAME}-${APP_VERSION}..."
unzip "${APP_NAME}-${APP_VERSION}.zip"
sh "${APP_NAME}-${APP_VERSION}/bin/${APP_NAME}"
echo "Application exited"'
```

By default the collector processes only builds from the moment the app is started, but you can collect past builds by setting `export BACKFILL_DAYS=<number>` in the startup script.

Similarly, you can specify a `export LAST_BUILD_ID="jh4qknspatp2y"` to start streaming from the build _immediately after_ the given build ID.

==== Running a Build Event Indexer

```sh
gcloud compute instances create build-event-indexerator1 \
   --preemptible \
   --image-family debian-9 \
   --image-project debian-cloud \
   --machine-type n1-standard-4 \
   --scopes "userinfo-email,cloud-platform" \
   --metadata startup-script='#!/bin/sh
APP_NAME="build-event-indexerator"
APP_VERSION="0.2.0"
export GCS_RAW_BUCKET_NAME="gradle-task-test-cache-events-raw"
export GCS_TRANSFORMED_BUCKET_NAME="gradle-task-test-cache-events"
export BIGQUERY_DATASET_NAME="gradle_builds"
export BIGQUERY_TABLE_NAME="builds_20190115"
gsutil cp "gs://gradle-build-analysis-apps/maven2/org/gradle/buildeng/analysis/${APP_NAME}/${APP_VERSION}/${APP_NAME}-${APP_VERSION}.zip" .
apt-get update && apt-get -y --force-yes install openjdk-8-jdk unzip
update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
echo "Running ${APP_NAME}-${APP_VERSION}..."
unzip "${APP_NAME}-${APP_VERSION}.zip"
sh "${APP_NAME}-${APP_VERSION}/bin/${APP_NAME}"
echo "Application exited"'
```

==== Getting logs for a given instance
```sh
gcloud compute instances get-serial-port-output build-event-collectorator1
```
